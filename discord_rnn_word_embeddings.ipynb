{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaileyDalton007/discord_rnn/blob/main/discord_rnn_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fHzEA7of1kmL"
      },
      "outputs": [],
      "source": [
        "from gensim.models.word2vec import Word2Vec as w2v\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Matplotlib outputs tons of warning for missing characters\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-qKktUe5F2D"
      },
      "outputs": [],
      "source": [
        "# Upload training csv's\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX9r38U810up"
      },
      "outputs": [],
      "source": [
        "file_names = list(uploaded.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu1w01w45Y3x"
      },
      "outputs": [],
      "source": [
        "from os import linesep\n",
        "# Create master array for messages from all files\n",
        "msg_array = []\n",
        "\n",
        "for file in file_names:\n",
        "  with open(file, 'r', encoding='utf8') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "\n",
        "    for row in csv_reader:\n",
        "      msg_array.append(row[0].lower())\n",
        "\n",
        "# Tokenize msg_array\n",
        "msg_array = [sub.split() for sub in msg_array]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If model already trained and saved, load it.\n",
        "model_save_file = files.upload()\n",
        "model = w2v.load('word2vec.model')"
      ],
      "metadata": {
        "id": "0v74ejsWEXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyzgRPs-1pqu"
      },
      "outputs": [],
      "source": [
        "# Train word2vec model, may take a bit\n",
        "model = w2v(msg_array, min_count=2, size = 5, window = 5)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('word2vec.model')\n",
        "files.download('word2vec.model')"
      ],
      "metadata": {
        "id": "jzcEqv4lEDc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IrsR-RN71usU"
      },
      "outputs": [],
      "source": [
        "vocab = list(model.wv.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF09eLJW1wpI"
      },
      "outputs": [],
      "source": [
        "print(model.wv.__getitem__('cars'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukgGKEgz1y67"
      },
      "outputs": [],
      "source": [
        "# This is horrendous please don't\n",
        "\n",
        "X = model.wv.__getitem__(model.wv.vocab)\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "result = pca.fit_transform(X)\n",
        "\n",
        "# Create a scatter plot of the projection\n",
        "plt.scatter(result[:, 0], result[:, 1])\n",
        "words = list(model.wv.vocab)\n",
        "\n",
        "for i, word in enumerate(words):\n",
        "   plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgduRGCQ-Y1I"
      },
      "outputs": [],
      "source": [
        "# Pass the embeddings to PCA\n",
        "X = model.wv.__getitem__(model.wv.vocab)\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(X)\n",
        "\n",
        "# Create df from the pca results\n",
        "pca_df = pd.DataFrame(result, columns = ['x','y'])\n",
        "\n",
        "# Add the words for the hover effect\n",
        "pca_df['word'] = words\n",
        "pca_df.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "discord_rnn_word_embeddings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSSLKLJeGi0pTYhxW4KB9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}